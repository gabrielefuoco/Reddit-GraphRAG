# Relazione del Progetto: Analizzatore di Opinioni Politiche su Reddit (GraphRAG)

## Abstract

Questo documento presenta un'analisi dettagliata di un sistema end-to-end per l'analisi delle discussioni politiche sulla piattaforma Reddit. Il progetto implementa una pipeline GraphRAG (Retrieval-Augmented Generation) che trasforma il contenuto testuale non strutturato in un knowledge graph strutturato e interrogabile, ospitato su un database Neo4j. L'obiettivo principale è superare i limiti delle tradizionali ricerche basate su keyword e dei sistemi RAG puramente vettoriali, offrendo un'analisi semantica più profonda e contestualizzata delle opinioni politiche. Il sistema impiega una strategia di recupero ibrido a due stadi: le query vengono prima risolte interrogando la struttura del grafo per identificare entità e relazioni pertinenti; i risultati vengono poi riordinati semanticamente attraverso la similarità vettoriale per massimizzare la rilevanza. In caso di fallimento, il sistema esegue in modo trasparente una ricerca vettoriale pura sull'intero dataset. I dati raccolti da Reddit vengono sottoposti a un'analisi NLP approfondita, che include l'estrazione di entità nominate (NER), il rilevamento della stance e la generazione di embedding vettoriali. Vengono inoltre applicati algoritmi di analisi di grafi (Leiden) per identificare cluster di utenti con allineamenti ideologici simili. L'interfaccia utente, costruita con Streamlit, fornisce un punto di accesso intuitivo per esplorare i dati e interagire con l'agente di ragionamento.

## 1. Introduzione

### 1.1. Contesto

Nell'era digitale, i social media sono diventati una fonte inesauribile di dati testuali non strutturati, che riflettono le opinioni e i sentimenti del pubblico su una vasta gamma di argomenti, in particolare in ambito politico. L'analisi di questi dati offre opportunità senza precedenti per comprendere le dinamiche sociali, le tendenze dell'opinione pubblica e le narrative politiche emergenti. Tuttavia, la vastità, la complessità e la natura non strutturata di questi dati presentano sfide significative per l'analisi.

Le tecniche tradizionali di analisi del testo, come la ricerca basata su keyword, si rivelano spesso inadeguate a cogliere le sfumature e il contesto del linguaggio naturale. D'altra parte, i moderni approcci basati su modelli linguistici di grandi dimensioni (LLM), pur essendo potenti, possono mancare di specificità e soffrire di "allucinazioni" se non ancorati a una solida base di conoscenza fattuale.

In questo contesto, le architetture RAG (Retrieval-Augmented Generation) sono emerse come una soluzione promettente, combinando la capacità di recupero di informazioni da una base di conoscenza con la potenza generativa degli LLM. Tuttavia, anche i sistemi RAG basati su database vettoriali possono avere difficoltà a cogliere le relazioni complesse e implicite tra le entità.

Il presente progetto si inserisce in questo filone di ricerca, proponendo un'evoluzione del paradigma RAG attraverso l'adozione di un'architettura GraphRAG. Sfruttando la potenza dei knowledge graph, il sistema mira a modellare esplicitamente le relazioni tra utenti, post, entità politiche e opinioni, consentendo un'analisi più profonda e contestualizzata delle discussioni politiche su Reddit.

### 1.2. Obiettivi

Il progetto si pone i seguenti obiettivi principali:

1.  **Costruire un Knowledge Graph Politico**: Creare un grafo della conoscenza strutturato e semanticamente ricco a partire dai dati non strutturati raccolti da subreddit politici, modellando le relazioni tra utenti, post, commenti, entità politiche e opinioni.
2.  **Implementare una Pipeline di Arricchimento NLP Avanzata**: Sviluppare una pipeline di elaborazione del linguaggio naturale per estrarre informazioni chiave dai testi, tra cui:
    * **Estrazione di Entità Nominate (NER)**: Per identificare figure, organizzazioni e concetti politici.
    * **Rilevamento della Stance**: Per classificare le opinioni come favorevoli, contrarie o neutrali.
    * **Generazione di Embedding Vettoriali**: Per catturare il significato semantico del testo.
3.  **Sviluppare un Sistema di Recupero Ibrido**: Creare un sistema di recupero delle informazioni a due stadi che combini la ricerca strutturata sul grafo con la ricerca semantica basata su vettori, garantendo risposte pertinenti e contestualizzate.
4.  **Analizzare le Comunità e le Ideologie**: Applicare algoritmi di graph analysis per identificare cluster di utenti con allineamenti ideologici simili e generare riassunti semantici delle loro posizioni.
5.  **Creare un Agente Conversazionale Intuitivo**: Sviluppare un'interfaccia utente interattiva basata su Streamlit che consenta agli utenti di interrogare il knowledge graph in linguaggio naturale e di esplorare i dati in modo visuale.

### 1.3. Architettura del Sistema

L'architettura del sistema è suddivisa in due fasi principali: una pipeline offline per la costruzione e l'arricchimento del grafo e una pipeline online for l'interrogazione in tempo reale.

* **Fase 1: Costruzione del Knowledge Graph**: Questa fase è orchestrata dallo script `run_pipeline.py` e si articola nei seguenti passaggi:
    1.  **Ingestione dei Dati**: I dati vengono raccolti da una lista predefinita di subreddit (`politics`, `PoliticalDiscussion`, `Conservative`, `Liberal`, `antiwork`, `changemyview`) tramite l'API di Reddit, utilizzando la libreria `asyncpraw`.
    2.  **Pulizia e Preprocessing**: Il testo grezzo viene pulito e pre-elaborato utilizzando `spaCy` per la lemmatizzazione e la rimozione delle stop word.
    3.  **Analisi NLP**: Il testo pulito viene arricchito con informazioni semantiche attraverso l'estrazione di entità, il rilevamento della stance e la generazione di embedding vettoriali.
    4.  **Costruzione del Grafo**: I dati arricchiti vengono caricati in un database Neo4j, creando un grafo che modella le relazioni tra utenti, post, commenti ed entità politiche.
    5.  **Defragmentazione delle Entità**: Viene eseguito un processo di clustering per identificare e unire le entità duplicate o sinonime.
    6.  **Analisi del Grafo**: Vengono applicati algoritmi della libreria Neo4j Graph Data Science (GDS), come Leiden, per la community detection e vengono generati riassunti semantici delle ideologie identificate.

* **Fase 2: Interrogazione**: L'interazione con il sistema avviene tramite un'applicazione web sviluppata con Streamlit:
    1.  **Interfaccia Utente**: L'utente inserisce una query in linguaggio naturale.
    2.  **Agente ReAct**: La query viene gestita da un agente LangChain di tipo ReAct, che orchestra l'interazione con gli strumenti a sua disposizione.
    3.  **Pipeline GraphRAG**: L'agente utilizza la pipeline GraphRAG per recuperare le informazioni pertinenti dal knowledge graph, combinando la ricerca strutturata e quella semantica.
    4.  **Generazione della Risposta**: Il contesto recuperato viene passato a un LLM, che genera una risposta in linguaggio naturale.
    5.  **Visualizzazione**: La risposta viene visualizzata nell'interfaccia utente, che offre anche strumenti per l'esplorazione visuale del grafo.

Lo stack tecnologico del progetto include Python, Streamlit per l'interfaccia web, Neo4j come database a grafo, PRAW per l'ingestione dei dati, spaCy e Hugging Face Transformers per l'elaborazione NLP, Sentence-Transformers per la generazione di embedding e LangChain per l'orchestrazione dell'LLM.

La presente relazione è strutturata come segue: il Capitolo 2 descrive l'architettura generale del sistema. Il Capitolo 3 approfondisce la pipeline di acquisizione e trasformazione dei dati. I Capitoli 4 e 5 si concentrano sul cuore del sistema: la pipeline GraphRAG e l'agente conversazionale. Infine, il Capitolo 6 illustra l'interfaccia utente e presenta le conclusioni e gli sviluppi futuri."