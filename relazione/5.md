## 5. L'Agente Conversazionale e l'Ingegneria dei Prompt

Per rendere il complesso knowledge graph interrogabile in modo intuitivo, è stato sviluppato un agente conversazionale. Questo agente funge da intermediario intelligente tra l'utente e la pipeline GraphRAG, interpretando le domande in linguaggio naturale e orchestrando le azioni necessarie per trovare una risposta. L'efficacia di questo agente, e dell'intero sistema NLP, si basa su un'attenta ingegneria dei prompt (prompt engineering), che guida il comportamento dei Large Language Models (LLM) in ogni fase del processo.

### 5.1. L'Agente ReAct: Ragionare e Agire

La scelta architetturale per l'agente è ricaduta sul framework **ReAct (Reasoning and Acting)**, implementato tramite la libreria LangChain. A differenza di approcci più semplici che collegano direttamente l'input dell'utente a uno strumento, un agente ReAct emula un processo di ragionamento umano.

Il ciclo operativo di un agente ReAct è il seguente:
1.  **Thought (Pensiero)**: L'agente analizza la domanda dell'utente e la cronologia della conversazione. Formula un'ipotesi su ciò che l'utente sta chiedendo e pianifica quale strumento utilizzare per trovare la risposta.
2.  **Action (Azione)**: L'agente seleziona uno strumento dal suo arsenale (in questo caso, lo strumento `political_analyzer`) e definisce l'input per quello strumento.
3.  **Observation (Osservazione)**: L'agente esegue lo strumento e ne osserva l'output.
4.  **Loop o Risposta Finale**: L'agente analizza l'osservazione. Se l'informazione è sufficiente per rispondere alla domanda originale, formula una `Final Answer`. Altrimenti, ricomincia il ciclo con un nuovo `Thought`, utilizzando l'informazione appena ottenuta per pianificare il passo successivo.

Questo approccio iterativo rende l'agente più robusto e flessibile. È in grado di scomporre problemi complessi, di gestire dialoghi multi-turno e di mostrare (in fase di debug) il suo "flusso di pensiero", rendendo il suo comportamento più trasparente e interpretabile.

#### 5.1.1. Lo Strumento a Disposizione: `political_analyzer`

L'agente è deliberatamente minimalista: ha accesso a un solo, potente strumento chiamato `political_analyzer`. Questo strumento è un wrapper attorno alla `GraphRAGPipeline.query`. La sua descrizione, fornita all'agente, è cruciale: *"Use this tool to answer questions about political opinions, criticism, support or analysis regarding political figures, organizations or concepts. Input should be the complete user question."*. Questa descrizione guida l'agente su *quando* e *come* utilizzare lo strumento, che di fatto incapsula tutta la logica di interrogazione del grafo.

#### 5.1.2. Il Prompt Principale dell'Agente (`AGENT_PROMPT_TEMPLATE`)

Il comportamento dell'agente ReAct è definito dal suo prompt principale, `AGENT_PROMPT_TEMPLATE`. Questo prompt è una vera e propria "costituzione" per l'agente e contiene diverse sezioni chiave:
* **Ruolo**: "You are a reasoning agent. Your mission is to answer the user's question using the provided tools."
* **Strumenti (`{tools}`)**: Una sezione che descrive dinamicamente gli strumenti disponibili.
* **Cronologia della Conversazione (`{chat_history}`)**: Permette all'agente di avere memoria delle interazioni passate, consentendo domande di follow-up.
* **Formato di Risposta**: Una sezione estremamente rigida che impone la struttura `Thought: ... Action: ... Action Input: ... Observation: ...`. Questa formattazione è essenziale perché l'output dell'LLM possa essere parsato correttamente dal framework LangChain.
* **Regola Critica**: Una regola esplicita ("CRITICAL RULE") che forza l'agente a fornire una `Final Answer` non appena l'osservazione contiene informazioni sufficienti, per evitare loop inutili.

### 5.2. I Prompt del Core NLP (`src/llm/core.py`)

Oltre al prompt dell'agente, il sistema si affida a una serie di prompt specializzati per le attività NLP di basso livello, tutte definite in `src/llm/core.py`. Ogni prompt è progettato per essere il più preciso e non ambiguo possibile, utilizzando tecniche come il "few-shot learning" (fornendo esempi) per guidare l'LLM.

* **`entity_prompt_template` (Estrazione Entità)**:
    * **Ruolo**: "You are a high-precision Named Entity Recognition model."
    * **Istruzioni**: Regole ferree sul formato dell'output (JSON con una singola chiave "entities"), sulla gestione dei casi senza entità (lista vuota) e sulla normalizzazione (es. "Biden" per "Joe Biden").
    * **Esempi (Few-shot)**: Vengono forniti esempi di input/output per diversi scenari (entità singola, multipla, nessuna entità), che aiutano il modello a "imparare" il formato e il livello di astrazione richiesto.

* **`stance_prompt_template` (Rilevamento Stance)**:
    * **Ruolo**: "You are a Stance Classifier."
    * **Istruzioni**: Definisce chiaramente le tre categorie (`FAVORABLE`, `AGAINST`, `NEUTRAL`) e, cosa fondamentale, specifica che `NEUTRAL` deve essere usato "ONLY for purely factual statements". Questo spinge il modello a prendere una posizione se è presente anche un minimo di linguaggio opinabile.
    * **Output**: Richiede un JSON con le chiavi "stance" e "confidence".

* **`stance_contextual_prompt_template` (Stance Contestuale)**:
    * **Ruolo**: "You are a high-precision contextual stance detection analyst."
    * **Contesto**: Questo prompt ha una struttura più complessa. Accetta tre input: il contenuto del post originale (`ORIGINAL POST`), il commento da analizzare (`COMMENT`), e l'entità target (`ENTITY`).
    * **Istruzioni**: Enfatizza che il post originale serve "for context only" e che l'analisi deve essere "strictly towards the specified ENTITY". Questo previene che l'LLM confonda la stance del post con quella del commento.

* **`summary_prompt_template` (Riassunto)**:
    * **Ruolo**: "You are an expert political analyst and narrative summarizer."
    * **Obiettivo**: Il prompt non chiede un semplice riassunto, ma una "comprehensive, well-structured summary" che catturi temi, opinioni, tono e citazioni ricorrenti.
    * **Stile e Struttura**: Fornisce linee guida dettagliate sullo stile di scrittura (fluente, analitico, in italiano) e suggerisce una struttura in paragrafi (panoramica, temi chiave, sentiment, conclusione), guidando l'LLM a produrre un output di alta qualità giornalistica.

* **`rag_prompt_template` (Generazione RAG)**:
    * **Ruolo**: "You are a political analyst AI."
    * **Regola Fondamentale**: "Your sole function is to answer the user's question using ONLY the provided context." Questa è la regola anti-allucinazione.
    * **Processo di Pensiero Interno**: Il prompt include una sezione (che l'LLM non deve mostrare nell'output) che gli spiega come dovrebbe "pensare": identificare le informazioni rilevanti, sintetizzare i fatti, e gestire i punti di vista contrastanti.
    * **Regole di Output**: Definisce lo stile della risposta (professionale, dettagliato), incoraggia l'uso di citazioni e, crucialmente, fornisce una risposta di fallback esatta ("Non ho abbastanza informazioni...") nel caso in cui il contesto sia insufficiente.

Questa architettura a più livelli, con un agente ReAct che orchestra l'interazione e una serie di prompt specializzati che pilotano con precisione le capacità dell'LLM, consente al sistema di gestire conversazioni complesse e di eseguire analisi NLP sfaccettate in modo controllato e affidabile.
