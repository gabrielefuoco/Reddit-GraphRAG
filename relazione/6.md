## 6. Interfaccia Utente e Visualizzazione dei Dati

Per rendere accessibili le complesse analisi prodotte dalla pipeline, è stata sviluppata un'interfaccia utente web utilizzando **Streamlit**. Questa scelta è motivata dalla rapidità di sviluppo e dalla facilità con cui è possibile creare applicazioni data-centriche interattive in Python. Il punto di ingresso dell'applicazione è il file `app.py`, che orchestra la UI e gestisce l'interazione con il backend.

L'interfaccia è stata progettata per essere pulita, intuitiva e per servire due scopi principali: l'interrogazione conversazionale del knowledge graph e l'esplorazione analitica delle entità politiche. L'utente può navigare tra queste due modalità tramite una selectbox nella sidebar.

### 6.1. Vista "Chat": Interazione Conversazionale

Questa è la vista principale dell'applicazione, progettata per l'interazione diretta con l'agente ReAct.

* **Interfaccia di Chat**: La UI emula una moderna applicazione di messaggistica. La cronologia della conversazione viene mantenuta e visualizzata, permettendo all'utente di seguire il filo del dialogo. Lo stato della chat è gestito all'interno della sessione di Streamlit (`st.session_state.messages`), garantendo che la conversazione persista durante la navigazione.
* **Integrazione con l'Agente**: Quando l'utente invia una domanda, questa viene passata come input all'esecutore dell'agente (`agent_executor.invoke`). È importante notare che non viene passata solo l'ultima domanda, ma l'intera cronologia della chat (opportunamente formattata in oggetti `HumanMessage` e `AIMessage` di LangChain). Questo fornisce all'agente il contesto completo della conversazione, abilitandolo a rispondere a domande di follow-up e a mantenere un dialogo coerente.
* **Feedback Visivo**: Durante l'elaborazione della risposta da parte dell'agente (che può richiedere alcuni secondi, data la complessità della pipeline RAG), viene mostrato un indicatore di caricamento (`st.spinner("Sto pensando...")`). Questo migliora l'esperienza utente, fornendo un feedback visivo che il sistema sta lavorando.
* **Gestione degli Errori**: In caso di problemi durante l'invocazione dell'agente (es. problemi di connessione a Neo4j o a Ollama), l'errore viene catturato e mostrato all'utente in un formato chiaro (`st.error`), prevenendo il crash dell'applicazione.

### 6.2. Vista "Panoramica Entità": Dashboard Analitica

Questa vista trasforma l'applicazione da un semplice chatbot a uno strumento di analisi esplorativa, permettendo all'utente di "zoomare" su specifiche entità politiche e di visualizzarne i dati aggregati.

* **Selezione dell'Entità**: La vista presenta una dropdown (`st.selectbox`) popolata dinamicamente con la lista di tutte le entità politiche uniche presenti nel database, ottenuta tramite la funzione `get_all_entities`. Questo permette all'utente di esplorare facilmente l'intero panorama delle entità discusse.
* **Recupero dei Dati**: Una volta selezionata un'entità, la funzione `get_entity_overview_data` esegue query Cypher specifiche per recuperare dati aggregati su di essa.
* **Visualizzazioni**: I dati recuperati vengono presentati attraverso due visualizzazioni principali, disposte in colonne per un layout efficace:
    1.  **Distribuzione delle Stance**: Un grafico a barre (`st.bar_chart`), generato utilizzando Pandas e Plotly (integrato in Streamlit), mostra il conteggio dei post per ciascuna stance (`FAVORABLE`, `AGAINST`, `NEUTRAL`) relativa all'entità selezionata. Questo fornisce una visione immediata e quantitativa del sentiment generale della comunità nei confronti dell'entità.
    2.  **Grafo delle Menzioni**: Utilizzando la libreria `streamlit-agraph`, viene renderizzato un grafo interattivo che mostra quali utenti (`User`) hanno menzionato l'entità selezionata (`PoliticalEntity`). I nodi rappresentano gli utenti e l'entità, mentre gli archi indicano la relazione di menzione. L'utente può zoomare, trascinare i nodi ed esplorare le connessioni, ottenendo un'idea della centralità di un'entità e degli attori principali che ne discutono.

### 6.3. Ottimizzazione delle Prestazioni

Per garantire un'esperienza utente fluida, sono state adottate alcune strategie di ottimizzazione:
* **Caching delle Risorse**: La connessione al driver Neo4j e l'inizializzazione dell'agente LangChain sono operazioni potenzialmente lente. Per evitare di ripeterle ad ogni interazione dell'utente, la funzione `init_connections` è decorata con `@st.cache_resource`. Questo fa sì che queste risorse vengano create una sola volta e riutilizzate per tutta la durata della sessione dell'utente, migliorando drasticamente la reattività dell'applicazione.

Questa interfaccia utente, bilanciando interazione conversazionale e visualizzazione analitica, riesce a esporre la potenza del knowledge graph sottostante in modo accessibile sia a utenti non tecnici interessati a porre domande, sia ad analisti che desiderano esplorare i dati in modo più approfondito.

## 7. Conclusioni e Sviluppi Futuri

### 7.1. Riepilogo e Risultati

Il progetto ha raggiunto con successo l'obiettivo di sviluppare un sistema end-to-end per l'analisi delle opinioni politiche su Reddit, basato su un'architettura GraphRAG. Il sistema è in grado di:
* **Trasformare dati non strutturati** in un knowledge graph ricco e interrogabile, catturando entità, relazioni e sentiment.
* **Implementare un recupero delle informazioni ibrido** che sfrutta sia la struttura del grafo che la semantica dei vettori, garantendo risposte pertinenti e contestualizzate.
* **Fornire un'interfaccia conversazionale intuitiva** tramite un agente ReAct, che permette un'interrogazione in linguaggio naturale.
* **Offrire strumenti di analisi visuale** che permettono un'esplorazione approfondita delle entità e delle loro relazioni all'interno del dataset.

Il principale punto di forza del progetto risiede nell'approccio olistico all'analisi, che va oltre la semplice classificazione del testo per modellare l'intero ecosistema della discussione, comprese le alleanze ideologiche tra utenti e la sintesi di prospettive complesse.

### 7.2. Limiti Attuali

Nonostante i risultati positivi, il sistema presenta alcuni limiti intrinseci e aree di potenziale miglioramento:
* **Copertura del Dataset**: L'analisi si basa su un campione di post e subreddit. Per quanto indicativo, non è statisticamente rappresentativo dell'intera piattaforma Reddit o dell'opinione pubblica in generale. È fondamentale riconoscere che il sistema può ereditare e amplificare bias presenti sia nei dati di origine (le comunità di Reddit potrebbero non essere rappresentative dello spettro politico generale) sia nei modelli LLM pre-addestrati, che possono riflettere pregiudizi presenti nei loro dati di training
* **Accuratezza dei Modelli NLP**: L'efficacia del sistema dipende fortemente dall'accuratezza dei modelli LLM utilizzati per NER e stance detection. Modelli generici possono avere difficoltà a interpretare il linguaggio altamente specialistico, sarcastico o codificato tipico delle comunità online.
* **Scalabilità della Pipeline**: La pipeline di ingestione, sebbene robusta, è eseguita come un unico script batch. Per dataset di dimensioni molto maggiori, questo approccio potrebbe diventare un collo di bottiglia.
* **Mancanza di Testing Formalizzato**: Come indicato nella documentazione, il progetto manca di una suite di test automatici (es. `pytest`), che è fondamentale per garantire la manutenibilità e l'affidabilità del codice nel lungo periodo.

### 7.3. Sviluppi Futuri

Basandosi sui limiti attuali e sulle potenzialità del sistema, si possono delineare diverse direzioni per lo sviluppo futuro:

1.  **Miglioramento dei Modelli NLP**:
    * **Fine-tuning**: Eseguire il fine-tuning dei modelli di NER e stance detection su un dataset specifico di discussioni politiche di Reddit, etichettato manualmente. Questo aumenterebbe drasticamente l'accuratezza e la capacità di gestire il gergo specifico del dominio.
    * **Valutazione dei Modelli**: Implementare un framework di valutazione rigoroso per misurare le performance dei modelli (es. F1-score, precision, recall) e della pipeline RAG nel suo complesso (es. RAGAs, ARES).

2.  **Evoluzione della Pipeline Dati**:
    * **Ingestione in Streaming**: Per un'analisi quasi in tempo reale, sostituire l'attuale ingestione batch con un'architettura basata su code di messaggi (es. RabbitMQ, Kafka), che permetterebbe di processare i post e i commenti man mano che vengono pubblicati.
    * **Data Lineage e Monitoraggio**: Introdurre strumenti per tracciare la provenienza dei dati e per monitorare la salute della pipeline.

3.  **Arricchimento dell'Analisi del Grafo**:
    * **Analisi Temporale**: Sfruttare i timestamp presenti sui dati per analizzare l'evoluzione delle discussioni e delle opinioni nel tempo.
    * **Link Prediction**: Utilizzare algoritmi di GDS per predire la formazione di nuove alleanze tra utenti o l'emergere di nuove discussioni.

4.  **Robustezza e Manutenibilità**:
    * **Suite di Test Completa**: Sviluppare test unitari e di integrazione per tutti i moduli critici del sistema, garantendo che future modifiche non introducano regressioni.
    * **Containerizzazione**: Utilizzare Docker e Docker Compose per containerizzare i vari servizi (applicazione Streamlit, API Ollama, database Neo4j), semplificando il deployment e garantendo la riproducibilità dell'ambiente di sviluppo.

In conclusione, questo progetto costituisce una solida base di partenza e una dimostrazione efficace delle potenzialità dell'approccio GraphRAG. Gli sviluppi futuri proposti potrebbero trasformarlo da un prototipo avanzato a un sistema di analisi politica di livello production, capace di fornire insight ancora più profondi e affidabili.